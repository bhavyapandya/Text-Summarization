{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3dd6ec9-f0b4-42e3-8062-318388499cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a02730d-4483-40e1-8c56-bf085dff63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"news_summary_more.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99951032-7851-453c-aba5-915973747feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    newString = re.sub(r'[^a-z0-9.\\s]','',text)\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19df05d-de70-420e-b7de-0f53c69f3e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        saurav kant an alumnus of upgrad and iiitbs pg...\n",
       "1        kunal shahs credit card bill payment platform ...\n",
       "2        new zealand defeated india by 8 wickets in the...\n",
       "3        with aegon life iterm insurance plan customers...\n",
       "4        speaking about the sexual harassment allegatio...\n",
       "                               ...                        \n",
       "98396    a crpf jawan was on tuesday axed to death with...\n",
       "98397    uff yeh the first song from the sonakshi sinha...\n",
       "98398    according to reports a new version of the 1999...\n",
       "98399    a new music video shows rapper snoop dogg aimi...\n",
       "98400    madhesi morcha an alliance of seven political ...\n",
       "Name: text, Length: 98401, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['headlines'].apply(clean)\n",
    "data['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea10efcf-d19c-4d72-8ae8-b23216f8a0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_TEXT_LEN = 0\n",
    "for i in data[\"text\"]:\n",
    "    if len(i.split())>MAX_TEXT_LEN:\n",
    "        MAX_TEXT_LEN = len(i.split())\n",
    "MAX_TEXT_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab4b9a5-3015-4442-9569-39b70484a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['headlines']=data['headlines'].apply(lambda x: 'sostok '+x+' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b60ab28-0092-447f-a5ba-1f678044e18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SUM_LEN = 0\n",
    "for i in data[\"headlines\"]:\n",
    "    if len(i.split())>MAX_SUM_LEN:\n",
    "        MAX_SUM_LEN = len(i.split())\n",
    "MAX_SUM_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "184700fc-b9d7-4187-9d83-b7d0313bd4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98401, 66)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "x_vocab = 15000\n",
    "x_tokenizer = Tokenizer(num_words=x_vocab)\n",
    "x_tokenizer.fit_on_texts(data[\"text\"].values)\n",
    "X = x_tokenizer.texts_to_sequences(data[\"text\"].values)\n",
    "X = pad_sequences(X, maxlen=MAX_TEXT_LEN, padding=\"post\")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a0d101-6577-4517-9698-54d2f9877ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98401, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vocab = 10000\n",
    "y_tokenizer = Tokenizer(num_words=y_vocab)\n",
    "y_tokenizer.fit_on_texts(data[\"headlines\"].values)\n",
    "Y = y_tokenizer.texts_to_sequences(data[\"headlines\"].values)\n",
    "Y = pad_sequences(Y,maxlen=MAX_SUM_LEN, padding=\"post\")\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32c6db50-86e4-4a5b-b35e-9b3ceb248d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(X, Y, train_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c61fd7e5-a46e-425a-9b8f-934686dc99b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "#making encoder model\n",
    "embedded_dim = 100\n",
    "latent_dim = 300\n",
    "\n",
    "encoder_input = Input(shape=(MAX_TEXT_LEN,))\n",
    "encoder_emb_layer = Embedding(x_vocab, embedded_dim)\n",
    "encoder_emb = encoder_emb_layer(encoder_input)\n",
    "encoder_lstm = LSTM(latent_dim, recurrent_dropout=0.4, dropout=0.4, return_sequences=True, return_state=True)\n",
    "encoder_output, state_h, state_c = encoder_lstm(encoder_emb)\n",
    "\n",
    "#decoding layer\n",
    "decoder_input = Input(shape=(None,))\n",
    "decoder_emb_layer = Embedding(y_vocab, embedded_dim)\n",
    "decoder_emb = decoder_emb_layer(decoder_input)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_output, decoder_state_h, decoder_state_c = decoder_lstm(decoder_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(y_vocab, activation=\"softmax\"))\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "model = Model(inputs=[encoder_input, decoder_input], outputs=decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c10586e-82fd-4628-bc0e-71a0d86f5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b96765-56c6-469a-8daa-f52143d0480f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "154/154 [==============================] - 362s 2s/step - loss: 4.0748 - accuracy: 0.5024 - val_loss: 3.7364 - val_accuracy: 0.5345\n",
      "Epoch 2/50\n",
      " 39/154 [======>.......................] - ETA: 2:49 - loss: 3.6895 - accuracy: 0.5339"
     ]
    }
   ],
   "source": [
    "model.fit([x_tr,y_tr[:,:-1]],y_tr.reshape(y_tr.shape[0],y_tr.shape[1],1)[:,1:], epochs=50, batch_size=128, validation_data=([x_val,y_val[:,:-1]],y_val.reshape(y_val.shape[0],y_val.shape[1],1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1105551a-88f5-484e-92b6-cb54b6c66d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making inference model for prediction\n",
    "\n",
    "#for encoder model\n",
    "encoder_model = Model(inputs=[encoder_input], outputs=[encoder_output,state_h,state_c])\n",
    "\n",
    "decoder_internal_state_h = Input(shape=(latent_dim,))\n",
    "decoder_internal_state_c = Input(shape=(latent_dim,))\n",
    "decoder_internal_states = [decoder_internal_state_h, decoder_internal_state_c]\n",
    "\n",
    "\n",
    "dec_emb_2 = decoder_emb_layer(decoder_input)\n",
    "decoder_output, state_h2, state_c2 = decoder_lstm(dec_emb_2, initial_state=[decoder_internal_state_h, decoder_internal_state_c])\n",
    "decoder_output = decoder_dense(decoder_output)\n",
    "#for decoder model\n",
    "decoder_model = Model(inputs=[decoder_input,decoder_internal_states], outputs=[decoder_output,state_h2,state_c2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c9ac4e6-e273-42fd-a1dc-11f6272f3d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 66)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 66, 100)           1500000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 66, 300), (None,  481200    \n",
      "=================================================================\n",
      "Total params: 1,981,200\n",
      "Trainable params: 1,981,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aeb6575-eac1-4eed-baa0-a10d707aaeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    1000000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 300),  481200      embedding_1[2][0]                \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 10000)  3010000     lstm_1[2][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,491,200\n",
      "Trainable params: 4,491,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a897a2d9-d1d5-4a99-a289-b170748b3b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d08078b5-e595-4534-99b1-b74ecf984937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence():\n",
    "    e_out, e_h, e_c = encoder_model.predict(x_val[1].reshape(1, MAX_TEXT_LEN))\n",
    "    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    target_seq[0,0] = target_word_index['sostok']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_seq = ''\n",
    "    count = 0\n",
    "    while not stop_condition:\n",
    "        \n",
    "        output_tokens,state_h2,state_c2 = decoder_model.predict([target_seq,e_h,e_c])\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens)\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if sampled_token!='eostok':\n",
    "            decoded_seq+=' '+sampled_token\n",
    "            \n",
    "        if sampled_token == 'eostok' or len(decoded_seq.split()) >= MAX_SUM_LEN:\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = sampled_token_index\n",
    "        \n",
    "        e_h, e_c = state_h2, state_c2\n",
    "    return decoded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd981115-ff42-44ab-a584-7895e4af042b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " us to to to to to to in in\n"
     ]
    }
   ],
   "source": [
    "print(decode_sequence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235070fe-31bf-432b-8ad2-86aa39e59379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
